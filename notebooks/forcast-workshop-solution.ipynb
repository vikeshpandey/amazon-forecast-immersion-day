{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Immersion Day\n",
    "\n",
    "This notebook will serve as a template for the overall process of taking a non ideal time series dataset and integrating it into [Amazon Forecast](https://aws.amazon.com/forecast/).\n",
    "\n",
    "## Overview\n",
    "\n",
    "1. Introduction to Amazon Forecast\n",
    "1. Obtaining Your Data\n",
    "1. Fitting the Data to Forecast\n",
    "1. Determining Your Forecast Horizon (1st pass)\n",
    "1. Building Your Predictors\n",
    "1. Visualizing Predictors\n",
    "1. Making Decisions\n",
    "1. Next Steps\n",
    "\n",
    "\n",
    "## Introduction to Amazon Forecast\n",
    "\n",
    "If you are not familiar with Amazon Forecast you can learn more about this tool on these pages:\n",
    "\n",
    "* [Product Page](https://aws.amazon.com/forecast/)\n",
    "* [GitHub Sample Notebooks](https://github.com/aws-samples/amazon-forecast-samples)\n",
    "* [Product Docs](https://docs.aws.amazon.com/forecast/latest/dg/what-is-forecast.html)\n",
    "\n",
    "\n",
    "## Obtaining Your Data\n",
    "\n",
    "A critical requirement to use Amazon Forecast is to have access to time-series data for your selected use case. To learn more about time series data:\n",
    "\n",
    "1. [Wikipedia](https://en.wikipedia.org/wiki/Time_series)\n",
    "1. [Toward's Data Science Primer](https://towardsdatascience.com/the-complete-guide-to-time-series-analysis-and-forecasting-70d476bfe775)\n",
    "1. [O'Reilly Book](https://www.amazon.com/gp/product/1492041653/ref=ppx_yo_dt_b_search_asin_title?ie=UTF8&psc=1)\n",
    "\n",
    "For this exercise, we use the individual household electric power consumption dataset. (Dua, D. and Karra Taniskidou, E. (2017). UCI Machine Learning Repository [http://archive.ics.uci.edu/ml]. Irvine, CA: University of California, School of Information and Computer Science.) We aggregate the usage data hourly.\n",
    "\n",
    "To begin, use Pandas to read the CSV and to show a sample of the data.\n",
    "\n",
    "To begin the cell below will complete the following:\n",
    "\n",
    "1. Create a directory for the data files.\n",
    "1. Download the sample data into the directory.\n",
    "1. Extract the archive file into the directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the data downloaded, now we will import the Pandas library as well as a few other data science tools in order to inspect the information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from time import sleep\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.dates import DateFormatter\n",
    "import matplotlib.dates as mdates\n",
    "import dateutil.parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the libraries loaded, start by using the Pandas library to parse the CSV and render a simple dataframe of the historical information provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/item-demand-time.csv\", dtype = object, names=['timestamp','value','item'])\n",
    "df.drop(df.loc[df['item']!='client_12'].index, inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice in the output above there are 3 columns of data:\n",
    "\n",
    "1. The Timestamp\n",
    "1. A Value\n",
    "1. An Item\n",
    "\n",
    "These are the 3 key required pieces of information to generate a forecast with Amazon Forecast. More can be added but these 3 must always remain present.\n",
    "\n",
    "The dataset happens to span January 01, 2014 to Deceber 31, 2014. For our testing we would like to keep the last month of information in a different CSV. We are also going to save January to November to a different CSV as well.\n",
    "\n",
    "You may notice a variable named `df` this is a popular convention when using Pandas if you are using the library's dataframe object, it is similar to a table in a database. You can learn more here: https://pandas.pydata.org/pandas-docs/stable/getting_started/10min.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will convert the timestamp field to an index so that we can see the date ranges within the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('timestamp', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell will show the range of dates now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now move onto slicing the information to have a validation set and the train and test set.\n",
    "\n",
    "Given the data ranges from 2014-01-01 01:00:00 to 2014-11-29 23:00:00, first split data from January to October, then save the rest into another dataframe.\n",
    "\n",
    "The data from January to October will be used by Forecast for the training and test set, and then November to December will be used as the validation set later in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df = df.loc['2014-01-01':'2014-11-01']\n",
    "validation_df = df.loc['2014-11-01':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next take a look and confirm the date ranges on each dataframe line up to the timelines described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now export them to CSV files and place them into your `data` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_df.to_csv(\"../data/item-demand-time-train.csv\", header=False, index=True)\n",
    "validation_df.to_csv(\"../data/item-demand-time-validation.csv\", header=False, index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uploading your training data to S3\n",
    "\n",
    "At this time the data is ready to be sent to S3 where Forecast will use it later. The following cells will upload the data to S3.\n",
    "\n",
    "Please paste the Bucket Name and the Forecast Role ARN from your Cloudformation outputs section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iam = boto3.client(\"iam\")\n",
    "\n",
    "role_name = \"ForecastRoleID-4\"\n",
    "assume_role_policy_document = {\n",
    "    \"Version\": \"2012-10-17\",\n",
    "    \"Statement\": [\n",
    "        {\n",
    "          \"Effect\": \"Allow\",\n",
    "          \"Principal\": {\n",
    "            \"Service\": \"forecast.amazonaws.com\"\n",
    "          },\n",
    "          \"Action\": \"sts:AssumeRole\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "create_role_response = iam.create_role(\n",
    "    RoleName = role_name,\n",
    "    AssumeRolePolicyDocument = json.dumps(assume_role_policy_document)\n",
    ")\n",
    "\n",
    "# AmazonPersonalizeFullAccess provides access to any S3 bucket with a name that includes \"personalize\" or \"Personalize\" \n",
    "# if you would like to use a bucket with a different name, please consider creating and attaching a new policy\n",
    "# that provides read access to your bucket or attaching the AmazonS3ReadOnlyAccess policy to the role\n",
    "policy_arn = \"arn:aws:iam::aws:policy/AmazonForecastFullAccess\"\n",
    "iam.attach_role_policy(\n",
    "    RoleName = role_name,\n",
    "    PolicyArn = policy_arn\n",
    ")\n",
    "\n",
    "# Now add S3 support\n",
    "iam.attach_role_policy(\n",
    "    PolicyArn='arn:aws:iam::aws:policy/AmazonS3FullAccess',\n",
    "    RoleName=role_name\n",
    ")\n",
    "time.sleep(30) # wait for a minute to allow IAM role policy attachment to propagate\n",
    "\n",
    "role_arn = create_role_response[\"Role\"][\"Arn\"]\n",
    "print(role_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point thie next thing to do is import a file into Amazon Forecast, however we do not yet have anything in S3, so we will create a bucket, and upload our target file there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace this bucket name and your Role ARN \n",
    "\n",
    "bucket_name = \"pandvike-1706\"\n",
    "role_name = role_arn.split(\"/\")[1]\n",
    "\n",
    "target_time_series_filename =\"elec_data/item-demand-time-train.csv\"\n",
    "\n",
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(target_time_series_filename).upload_file(\"../data/item-demand-time-train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started With Forecast\n",
    "\n",
    "Now that all of the required data to get started exists, our next step is to build the dataset groups and datasets required for our problem. Inside Amazon Forecast a DatasetGroup is an abstraction that contains all the datasets for a particular collection of Forecasts. There is no information sharing between DatasetGroups so if you'd like to try out various alternatives to the schemas we create below, you could create a new DatasetGroup and make your changes inside its corresponding Datasets.\n",
    "\n",
    "The order of the process below will be as follows:\n",
    "\n",
    "1. Create a DatasetGroup for our POC.\n",
    "1. Create a `Target-Time-Series` Dataset.\n",
    "1. Attach the Dataset to the DatasetGroup.\n",
    "1. Import the data into the Dataset.\n",
    "1. Generate Forecasts with DeepAR+.\n",
    "1. Query the Forecast.\n",
    "1. Compare the forecast with the actual. \n",
    "\n",
    "\n",
    "The cell below defines a few global settings for our POC with the service.\n",
    "\n",
    "### Definitions:\n",
    "\n",
    "1. DATASET_FREQUENCY: How frequently the data is measured in our target_time_series file aka the train and test dataset.\n",
    "1. TIMESTAMP_FORMAT: The format used for our timestamp.\n",
    "1. project: Just a string that helps label the assets created later.\n",
    "1. datasetName: The name of the Dataset that will be created.\n",
    "1. datasetGroupName: The name of the dataset group that will be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_FREQUENCY = \"H\" \n",
    "TIMESTAMP_FORMAT = \"yyyy-MM-dd hh:mm:ss\"\n",
    "\n",
    "project = 'forecast_immersion_day_20'\n",
    "datasetName= project+'_ds_20'\n",
    "datasetGroupName= project +'_dsg_20'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the metada stored on this instance of a SageMaker Notebook determine the region we are operating in. If you are using a Jupyter Notebook outside of SageMaker simply define `region` as the string that indicates the region you would like to use for Forecast and S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/opt/ml/metadata/resource-metadata.json') as notebook_info:\n",
    "    data = json.load(notebook_info)\n",
    "    resource_arn = data['ResourceArn']\n",
    "    region = resource_arn.split(':')[3]\n",
    "print(region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure your AWS APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.Session(region_name=region) \n",
    "forecast = session.client(service_name='forecast') \n",
    "forecast_query = session.client(service_name='forecastquery')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Create the DatasetGroup, this will be the isolation level for all further work during this immersion day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DatasetGroup\n",
    "create_dataset_group_response = forecast.create_dataset_group(DatasetGroupName=datasetGroupName,\n",
    "                                                              Domain=\"CUSTOM\",\n",
    "                                                             )\n",
    "datasetGroupArn = create_dataset_group_response['DatasetGroupArn']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below will describe the DatasetGroup, not much is interesting until we add a dataset later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast.describe_dataset_group(DatasetGroupArn=datasetGroupArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Datasets inside Amazon Forecast require a schema to be defined, there are several that already exist within the service but in this immersion day you will create one from scratch. Note the structure of the dictionary below, it should mirror the CSV file you created earlier. This schema will be used when importing data to make sure that it is parsed correctly from your CSV into a format which Forecast can use for building your models and inferences later.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the schema of your dataset here. Make sure the order of columns matches the raw data files.\n",
    "schema ={\n",
    "   \"Attributes\":[\n",
    "      {\n",
    "         \"AttributeName\":\"timestamp\",\n",
    "         \"AttributeType\":\"timestamp\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"target_value\",\n",
    "         \"AttributeType\":\"float\"\n",
    "      },\n",
    "      {\n",
    "         \"AttributeName\":\"item_id\",\n",
    "         \"AttributeType\":\"string\"\n",
    "      }\n",
    "   ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Once the schema has been defined you can now create the dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=forecast.create_dataset(\n",
    "                    Domain=\"CUSTOM\",\n",
    "                    DatasetType='TARGET_TIME_SERIES',\n",
    "                    DatasetName=datasetName,\n",
    "                    DataFrequency=DATASET_FREQUENCY, \n",
    "                    Schema = schema\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Again the cell below will give the metrics about the Dataset now that it has been created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_datasetArn = response['DatasetArn']\n",
    "forecast.describe_dataset(DatasetArn=target_datasetArn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Before the Dataset can be used, it needs to be attached to a DatasetGroup, the cell below will do that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attach the Dataset to the Dataset Group:\n",
    "forecast.update_dataset_group(DatasetGroupArn=datasetGroupArn, DatasetArns=[target_datasetArn])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "At long last, it is time to import data into Amazon Forecast, the cell below will start the import process for you using all of the resources that you created earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally we can call import the dataset\n",
    "target_s3DataPath = \"s3://\"+bucket_name+\"/\"+target_time_series_filename\n",
    "datasetImportJobName = 'DSIMPORT_JOB_TARGET'\n",
    "ds_import_job_response=forecast.create_dataset_import_job(DatasetImportJobName=datasetImportJobName,\n",
    "                                                          DatasetArn=target_datasetArn,\n",
    "                                                          DataSource= {\n",
    "                                                              \"S3Config\" : {\n",
    "                                                                 \"Path\":target_s3DataPath,\n",
    "                                                                 \"RoleArn\": role_arn\n",
    "                                                              } \n",
    "                                                          },\n",
    "                                                          TimestampFormat=TIMESTAMP_FORMAT\n",
    "                                                         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "To see the status immediately after creating the job run the cell below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_import_job_arn=ds_import_job_response['DatasetImportJobArn']\n",
    "print(ds_import_job_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The cell below will run and poll every 30 seconds until the import process has completed. This process will take around 5 minutes to complete so feel free to stretch your legs if needed. After it completes the next step is to start building models, AKA Predictors with Amazon Forecast.\n",
    "\n",
    "Once it prints ACTIVE you are ready to move onto the next section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    dataImportStatus = forecast.describe_dataset_import_job(DatasetImportJobArn=ds_import_job_arn)['Status']\n",
    "    print(dataImportStatus)\n",
    "    if dataImportStatus != 'ACTIVE' and dataImportStatus != 'CREATE_FAILED':\n",
    "        sleep(30)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Creating Predictors\n",
    "\n",
    "Given that that our data is hourly and we want to generate a forecast on the hour, we will se the frequency to H or hourly. Amazon Forecast does limit your horizon to 500 of whatever your frequency interval is, that would mean 500 hours here or around 20 days into the future. For the purposes of this exercise though we are going to set the horizon to 24 hours.\n",
    "\n",
    "The cells below will define a few variables to be used with all of our models. Then there will be an API call to create each Predictor where they are based on ARIMA, Prophet, and DeepAR+ respectfully.\n",
    "\n",
    "### Definitions\n",
    "- forecast_frequency: The interval for the forecast, in this case hourly.\n",
    "- forecast_horizon: How many of the intervals to predict in a forecast.\n",
    "- number_of_backtest_windows: How many validation windows.\n",
    "- backtest_window_offset: How long the validation window is.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastHorizon = 4\n",
    "NumberOfBacktestWindows = 1\n",
    "BackTestWindowOffset = 24\n",
    "ForecastFrequency = \"H\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you will need to define the ARN for DeepAR+ algorithm so that you can train a predictor with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepAR_Plus_algorithmArn = 'arn:aws:forecast:::algorithm/Deep_AR_Plus'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us create a predictor which will build using the DeepAR+ algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepAR+ Specifics\n",
    "deepAR_plus_predictorName= project+'_deeparp_algo_20'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While creating the predictor, you interact with Amazon Forecast APIs. For documentation on which all parameters are required in the `create_predictor` method, please have a look at: https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/forecast.html#ForecastService.Client.create_predictor\n",
    "\n",
    "\n",
    "If you want Amazon Forecast to evaluate each algorithm and choose the one that minimizes the objective function, set `PerformAutoML` to `True`. The objective function is defined as the mean of the weighted p10, p50, and p90 quantile losses. \n",
    "\n",
    "When AutoML is enabled, the following properties are disallowed:\n",
    "- AlgorithmArn\n",
    "- HPOConfig\n",
    "- PerformHPO\n",
    "- TrainingParameters\n",
    "\n",
    "And if you set `PerformAutoML` to False then you need to supply all the above parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build DeepAR+:\n",
    "deeparp_create_predictor_response=forecast.create_predictor(PredictorName=deepAR_plus_predictorName, \n",
    "                                                  AlgorithmArn=deepAR_Plus_algorithmArn,\n",
    "                                                  ForecastHorizon=forecastHorizon,\n",
    "                                                  PerformAutoML= False,\n",
    "                                                  PerformHPO=False,\n",
    "                                                  EvaluationParameters= {\"NumberOfBacktestWindows\": NumberOfBacktestWindows, \n",
    "                                                                         \"BackTestWindowOffset\": BackTestWindowOffset}, \n",
    "                                                  InputDataConfig= {\"DatasetGroupArn\": datasetGroupArn},\n",
    "                                                  FeaturizationConfig= {\"ForecastFrequency\": ForecastFrequency, \n",
    "                                                                        \"Featurizations\": \n",
    "                                                                        [\n",
    "                                                                          {\"AttributeName\": \"target_value\", \n",
    "                                                                           \"FeaturizationPipeline\": \n",
    "                                                                            [\n",
    "                                                                              {\"FeaturizationMethodName\": \"filling\", \n",
    "                                                                               \"FeaturizationMethodParameters\": \n",
    "                                                                                {\"frontfill\": \"none\", \n",
    "                                                                                 \"middlefill\": \"zero\", \n",
    "                                                                                 \"backfill\": \"zero\"}\n",
    "                                                                              }\n",
    "                                                                            ]\n",
    "                                                                          }\n",
    "                                                                        ]\n",
    "                                                                       }\n",
    "                                                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predictor creation takes 20-25 minutes minutes or so to complete. So feel free to take a break here here, go grab a pint, really anything that is going to kill some time.\n",
    "\n",
    "The following while loop keeps track of the DeepAR+ predictor progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    status = forecast.describe_predictor(PredictorArn=deeparp_create_predictor_response['PredictorArn'])['Status']\n",
    "    print(status)\n",
    "    if status != 'ACTIVE' and status != 'CREATE_FAILED':\n",
    "        sleep(30)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the Predictors\n",
    "\n",
    "Once the Predictor is in an Active state you can get metrics about it to better understand its accuracy and behavior. These are computed based on the hold out periods we defined when building the Predictor. The metrics are meant to guide our decisions when we use a particular Predictor to generate a forecast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepAR+ Metrics\n",
    "deeparp_arn = deeparp_create_predictor_response['PredictorArn']\n",
    "deeparp_metrics = forecast.get_accuracy_metrics(PredictorArn=deeparp_arn)\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(deeparp_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Forecast\n",
    "\n",
    "The next phase is to generate a Forecast from the Predictor so we can see the results and understand visually how the model is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepAR+\n",
    "deeparp_forecastName = project+'_deeparp_algo_forecast'\n",
    "deeparp_create_forecast_response=forecast.create_forecast(ForecastName=deeparp_forecastName,\n",
    "                                                  PredictorArn=deeparp_arn)\n",
    "deeparp_forecast_arn = deeparp_create_forecast_response['ForecastArn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    status = forecast.describe_forecast(ForecastArn=deeparp_forecast_arn)['Status']\n",
    "    print(status)\n",
    "    if status != 'ACTIVE' and status != 'CREATE_FAILED':\n",
    "        sleep(30)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Forecast\n",
    "\n",
    "Once created, the forecast results are ready and you view them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecastResponse = forecast_query.query_forecast(\n",
    "    ForecastArn=deeparp_forecast_arn,\n",
    "    Filters={\"item_id\":\"client_12\"}\n",
    ")\n",
    "\n",
    "pp = pprint.PrettyPrinter()\n",
    "pp.pprint(forecastResponse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Your Forecast\n",
    "\n",
    "So far you have prepared your data, and generated your first Forecast. Now is the time to pull down the predictions from this Predictor, and compare them to the actual observed values. This will let us know the impact of accuracy based on the Forecast.\n",
    "\n",
    "You can extend the approaches here to compare multiple models or predictors and to determine the impact of improved accuracy on your use case.\n",
    "\n",
    "Setup\n",
    "* Plotting the Actual Results\n",
    "* Plotting the Prediction\n",
    "* Comparing the Prediction to Actual Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the Actual Results\n",
    "\n",
    "we are now going to select a given date and customer from that dataframe and are going to plot the actual usage data for that customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_df = pd.read_csv(\"../data/item-demand-time-validation.csv\", names=['timestamp','value','item'])\n",
    "actual_df.head()\n",
    "\n",
    "#Next we need to reduce the data to just the day we wish to plot, which is the First of November 2014.\n",
    "actual_df = actual_df[(actual_df['timestamp'] >= '2014-11-01 00:00:00') & (actual_df['timestamp'] < '2014-11-01 04:00:00')]\n",
    "\n",
    "\n",
    "#Lastly, only grab the items for client_12\n",
    "\n",
    "actual_df = actual_df[(actual_df['item'] == 'client_12')]\n",
    "actual_df.head()\n",
    "actual_df.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Plotting the Prediction:\n",
    "\n",
    "Next we need to convert the JSON response from the Predictor to a dataframe that we can plot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate DF \n",
    "prediction_df_p10 = pd.DataFrame.from_dict(forecastResponse['Forecast']['Predictions']['p10'])\n",
    "prediction_df_p10.head()\n",
    "\n",
    "# Plot\n",
    "prediction_df_p10.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above merely did the p10 values, now do the same for p50 and p90."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_df_p50 = pd.DataFrame.from_dict(forecastResponse['Forecast']['Predictions']['p50'])\n",
    "prediction_df_p90 = pd.DataFrame.from_dict(forecastResponse['Forecast']['Predictions']['p90'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Comparing the Prediction to Actual Results\n",
    "\n",
    "After obtaining the dataframes the next task is to plot them together to determine the best fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# We start by creating a dataframe to house our content, here source will be which dataframe it came from\n",
    "results_df = pd.DataFrame(columns=['timestamp', 'value', 'source'])\n",
    "\n",
    "\n",
    "\n",
    "# Import the observed values into the dataframe:\n",
    "\n",
    "for index, row in actual_df.iterrows():\n",
    "    clean_timestamp = dateutil.parser.parse(row['timestamp'])\n",
    "    results_df = results_df.append({'timestamp' : clean_timestamp , 'value' : row['value'], 'source': 'actual'} , ignore_index=True)\n",
    "    \n",
    "    \n",
    "\n",
    "# To show the new dataframe\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now add the P10, P50, and P90 Values\n",
    "for index, row in prediction_df_p10.iterrows():\n",
    "    clean_timestamp = dateutil.parser.parse(row['Timestamp'])\n",
    "    results_df = results_df.append({'timestamp' : clean_timestamp , 'value' : row['Value'], 'source': 'p10'} , ignore_index=True)\n",
    "for index, row in prediction_df_p50.iterrows():\n",
    "    clean_timestamp = dateutil.parser.parse(row['Timestamp'])\n",
    "    results_df = results_df.append({'timestamp' : clean_timestamp , 'value' : row['Value'], 'source': 'p50'} , ignore_index=True)\n",
    "for index, row in prediction_df_p90.iterrows():\n",
    "    clean_timestamp = dateutil.parser.parse(row['Timestamp'])\n",
    "    results_df = results_df.append({'timestamp' : clean_timestamp , 'value' : row['Value'], 'source': 'p90'} , ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets draw a comparison of p10, p50 and p90 with the actual consumption values to see which of these quantiles is best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df = results_df.pivot(columns='source', values='value', index=\"timestamp\")\n",
    "\n",
    "pivot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_df.plot(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup\n",
    "\n",
    "The last thing to do now is to tear down the resources that you created in this exercise. The cell below will save a series of variables that are useful in this process. Execute it and then open the Cleanup.ipynb notebook to finish this process."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
